use regex::Regex;

use crate::constants::{SCROLL_ACCEL_INCREMENT, SCROLL_ACCEL_MAX};
use crate::persistence::{delete_message, log_error, save_message};
use crate::state::{estimate_tokens, ContextElement, ContextType, Message, MessageStatus, MessageType, State};

/// Remove LLM's mistaken ID prefixes like "[A84]: " from responses
pub fn clean_llm_id_prefix(content: &str) -> String {
    // First trim leading whitespace
    let trimmed = content.trim_start();

    // Pattern: one or more [A##]: or [A###]: at the start, with optional whitespace between
    let re = Regex::new(r"^(\[A\d+\]:\s*)+").unwrap();
    let cleaned = re.replace(trimmed, "").to_string();

    // Also clean any [Axx]: that appears at the start of lines (multiline responses)
    let re_multiline = Regex::new(r"(?m)^\[A\d+\]:\s*").unwrap();
    let result = re_multiline.replace_all(&cleaned, "").to_string();

    // Strip leading/trailing whitespace and newlines after cleaning
    result.trim().to_string()
}

/// Parse context selection patterns like p1, p-1, p_1, P1, P-1, P_1
/// Returns the context ID (e.g., "P1", "P28") if matched
pub fn parse_context_pattern(input: &str) -> Option<String> {
    let input = input.trim();
    if input.is_empty() {
        return None;
    }

    let input_lower = input.to_lowercase();

    // Must start with 'p'
    if !input_lower.starts_with('p') {
        return None;
    }

    // Get the rest after 'p'
    let rest = &input_lower[1..];

    // Skip optional separator (- or _)
    let num_str = if rest.starts_with('-') || rest.starts_with('_') {
        &rest[1..]
    } else {
        rest
    };

    // Parse the number and return the canonical ID format
    num_str.parse::<usize>().ok().map(|n| format!("P{}", n))
}

/// Find context index by ID
pub fn find_context_by_id(state: &State, id: &str) -> Option<usize> {
    state.context.iter().position(|c| c.id == id)
}

#[derive(Debug, Clone)]
pub enum Action {
    InputChar(char),
    InsertText(String),
    InputBackspace,
    InputDelete,
    InputSubmit,
    CursorWordLeft,
    CursorWordRight,
    DeleteWordLeft,
    RemoveListItem,  // Remove empty list item, keep newline
    CursorHome,
    CursorEnd,
    ClearConversation,
    NewContext,
    SelectNextContext,
    SelectPrevContext,
    AppendChars(String),
    StreamDone { _input_tokens: usize, output_tokens: usize },
    StreamError(String),
    ScrollUp(f32),
    ScrollDown(f32),
    StopStreaming,
    StartContextCleaning,
    TmuxSendKeys { pane_id: String, keys: String },
    TogglePerfMonitor,
    None,
}

pub enum ActionResult {
    Nothing,
    StartStream,
    StopStream,
    StartCleaning,
    Save,
    SaveMessage(String),
}

pub fn apply_action(state: &mut State, action: Action) -> ActionResult {
    // Reset scroll acceleration on non-scroll actions
    if !matches!(action, Action::ScrollUp(_) | Action::ScrollDown(_)) {
        state.scroll_accel = 1.0;
    }

    match action {
        Action::InputChar(c) => {
            state.input.insert(state.input_cursor, c);
            state.input_cursor += c.len_utf8();
            ActionResult::Nothing
        }
        Action::InsertText(text) => {
            state.input.insert_str(state.input_cursor, &text);
            state.input_cursor += text.len();
            ActionResult::Nothing
        }
        Action::InputBackspace => {
            if state.input_cursor > 0 {
                // Find the previous character boundary
                let prev = state.input[..state.input_cursor]
                    .char_indices()
                    .last()
                    .map(|(i, _)| i)
                    .unwrap_or(0);
                state.input.remove(prev);
                state.input_cursor = prev;
            }
            ActionResult::Nothing
        }
        Action::InputDelete => {
            if state.input_cursor < state.input.len() {
                state.input.remove(state.input_cursor);
            }
            ActionResult::Nothing
        }
        Action::CursorWordLeft => {
            if state.input_cursor > 0 {
                let before = &state.input[..state.input_cursor];
                // Skip whitespace, then skip word chars
                let trimmed = before.trim_end();
                if trimmed.is_empty() {
                    state.input_cursor = 0;
                } else {
                    let word_start = trimmed.rfind(|c: char| c.is_whitespace())
                        .map(|i| i + 1)
                        .unwrap_or(0);
                    state.input_cursor = word_start;
                }
            }
            ActionResult::Nothing
        }
        Action::CursorWordRight => {
            if state.input_cursor < state.input.len() {
                let after = &state.input[state.input_cursor..];
                // Skip current word chars, then skip whitespace
                let skip_word = after.find(|c: char| c.is_whitespace()).unwrap_or(after.len());
                let remaining = &after[skip_word..];
                let skip_space = remaining.find(|c: char| !c.is_whitespace()).unwrap_or(remaining.len());
                state.input_cursor += skip_word + skip_space;
            }
            ActionResult::Nothing
        }
        Action::DeleteWordLeft => {
            if state.input_cursor > 0 {
                let before = &state.input[..state.input_cursor];
                // Find word start (same logic as CursorWordLeft)
                let trimmed = before.trim_end();
                let word_start = if trimmed.is_empty() {
                    0
                } else {
                    trimmed.rfind(|c: char| c.is_whitespace())
                        .map(|i| i + 1)
                        .unwrap_or(0)
                };
                // Delete from word_start to cursor
                state.input = format!("{}{}", &state.input[..word_start], &state.input[state.input_cursor..]);
                state.input_cursor = word_start;
            }
            ActionResult::Nothing
        }
        Action::RemoveListItem => {
            // Remove the current line's content (empty list prefix) but keep the newline
            // Input: "- item\n- " -> "- item\n"
            if state.input_cursor > 0 {
                let before = &state.input[..state.input_cursor];
                // Find the last newline
                let line_start = before.rfind('\n').map(|i| i + 1).unwrap_or(0);
                // Delete from line_start to cursor
                state.input = format!("{}{}", &state.input[..line_start], &state.input[state.input_cursor..]);
                state.input_cursor = line_start;
            }
            ActionResult::Nothing
        }
        Action::CursorHome => {
            // Move to start of current line
            let before_cursor = &state.input[..state.input_cursor];
            state.input_cursor = before_cursor.rfind('\n').map(|i| i + 1).unwrap_or(0);
            ActionResult::Nothing
        }
        Action::CursorEnd => {
            // Move to end of current line
            let after_cursor = &state.input[state.input_cursor..];
            state.input_cursor += after_cursor.find('\n').unwrap_or(after_cursor.len());
            ActionResult::Nothing
        }
        Action::InputSubmit => {
            if state.input.is_empty() {
                return ActionResult::Nothing;
            }

            // Context switching is always allowed, even during streaming
            if let Some(id) = parse_context_pattern(&state.input) {
                if let Some(index) = find_context_by_id(state, &id) {
                    state.selected_context = index;
                    state.scroll_offset = 0.0;
                    state.user_scrolled = false;
                    state.input.clear();
                    state.input_cursor = 0;
                    return ActionResult::Nothing;
                }
            }

            let content = std::mem::take(&mut state.input);
            state.input_cursor = 0;
            let user_token_estimate = estimate_tokens(&content);

            // Assign user ID
            let user_id = format!("U{}", state.next_user_id);
            state.next_user_id += 1;

            let user_msg = Message {
                id: user_id,
                role: "user".to_string(),
                message_type: MessageType::TextMessage,
                content,
                content_token_count: user_token_estimate,
                tl_dr: None,
                tl_dr_token_count: 0,
                status: MessageStatus::Full,
                tool_uses: Vec::new(),
                tool_results: Vec::new(),
                input_tokens: 0,
            };
            save_message(&user_msg);

            // Add user message tokens to context
            if let Some(ctx) = state.context.get_mut(state.selected_context) {
                ctx.token_count += user_token_estimate;
            }

            // During streaming: insert BEFORE the streaming assistant message
            // Otherwise: append normally
            if state.is_streaming {
                // Insert before the last message (the streaming assistant message)
                let insert_pos = state.messages.len().saturating_sub(1);
                state.messages.insert(insert_pos, user_msg);
                return ActionResult::SaveMessage(state.messages[insert_pos].id.clone());
            }

            state.messages.push(user_msg);

            // Create assistant message and start streaming
            let assistant_id = format!("A{}", state.next_assistant_id);
            state.next_assistant_id += 1;

            let assistant_msg = Message {
                id: assistant_id,
                role: "assistant".to_string(),
                message_type: MessageType::TextMessage,
                content: String::new(),
                content_token_count: 0,
                tl_dr: None,
                tl_dr_token_count: 0,
                status: MessageStatus::Full,
                tool_uses: Vec::new(),
                tool_results: Vec::new(),
                input_tokens: 0,
            };
            state.messages.push(assistant_msg);

            state.is_streaming = true;
            state.streaming_estimated_tokens = 0;
            ActionResult::StartStream
        }
        Action::ClearConversation => {
            for msg in &state.messages {
                delete_message(&msg.id);
            }
            state.messages.clear();
            state.input.clear();
            // Reset token count for current context
            if let Some(ctx) = state.context.get_mut(state.selected_context) {
                ctx.token_count = 0;
            }
            ActionResult::Save
        }
        Action::NewContext => {
            let context_id = state.next_available_context_id();
            state.context.push(ContextElement {
                id: context_id,
                context_type: ContextType::Conversation,
                name: format!("Conv {}", state.context.len()),
                token_count: 0,
                file_path: None,
                file_hash: None,
                glob_pattern: None,
                glob_path: None,
                grep_pattern: None,
                grep_path: None,
                grep_file_pattern: None,
                tmux_pane_id: None,
                tmux_lines: None,
                tmux_last_keys: None,
                tmux_description: None,
                cached_content: None,
                cache_deprecated: false,
                last_refresh_ms: 0,
                tmux_last_lines_hash: None,
            });
            ActionResult::Save
        }
        Action::SelectNextContext => {
            if !state.context.is_empty() {
                state.selected_context = (state.selected_context + 1) % state.context.len();
                state.scroll_offset = 0.0;
                state.user_scrolled = false;
            }
            ActionResult::Nothing
        }
        Action::SelectPrevContext => {
            if !state.context.is_empty() {
                state.selected_context = if state.selected_context == 0 {
                    state.context.len() - 1
                } else {
                    state.selected_context - 1
                };
                state.scroll_offset = 0.0;
                state.user_scrolled = false;
            }
            ActionResult::Nothing
        }
        Action::AppendChars(text) => {
            if let Some(msg) = state.messages.last_mut() {
                if msg.role == "assistant" {
                    msg.content.push_str(&text);

                    // Update estimated token count during streaming
                    let new_estimate = estimate_tokens(&msg.content);
                    let added = new_estimate.saturating_sub(state.streaming_estimated_tokens);

                    if added > 0 {
                        if let Some(ctx) = state.context.get_mut(state.selected_context) {
                            ctx.token_count += added;
                        }
                        state.streaming_estimated_tokens = new_estimate;
                    }
                }
            }
            ActionResult::Nothing
        }
        Action::StreamDone { _input_tokens, output_tokens } => {
            state.is_streaming = false;

            // Correct the estimated tokens with actual output tokens
            if let Some(ctx) = state.context.get_mut(state.selected_context) {
                // Remove our estimate, add actual
                ctx.token_count = ctx.token_count
                    .saturating_sub(state.streaming_estimated_tokens)
                    .saturating_add(output_tokens);
            }
            state.streaming_estimated_tokens = 0;

            // Store actual token count on message and clean up LLM prefixes
            if let Some(msg) = state.messages.last_mut() {
                if msg.role == "assistant" {
                    // Remove any [A##]: prefixes the LLM mistakenly added
                    msg.content = clean_llm_id_prefix(&msg.content);
                    msg.content_token_count = output_tokens;
                    msg.input_tokens = _input_tokens;
                    let id = msg.id.clone();
                    return ActionResult::SaveMessage(id);
                }
            }
            ActionResult::Save
        }
        Action::StreamError(e) => {
            state.is_streaming = false;

            // Remove estimated tokens on error
            if let Some(ctx) = state.context.get_mut(state.selected_context) {
                ctx.token_count = ctx.token_count.saturating_sub(state.streaming_estimated_tokens);
            }
            state.streaming_estimated_tokens = 0;

            // Log error to file
            let error_file = log_error(&e);

            if let Some(msg) = state.messages.last_mut() {
                if msg.role == "assistant" {
                    msg.content = format!("[Error occurred. See details in {}]", error_file);
                    let id = msg.id.clone();
                    return ActionResult::SaveMessage(id);
                }
            }
            ActionResult::Save
        }
        Action::ScrollUp(amount) => {
            let accel_amount = amount * state.scroll_accel;
            state.scroll_offset = (state.scroll_offset - accel_amount).max(0.0);
            state.user_scrolled = true;
            state.scroll_accel = (state.scroll_accel + SCROLL_ACCEL_INCREMENT).min(SCROLL_ACCEL_MAX);
            ActionResult::Nothing
        }
        Action::ScrollDown(amount) => {
            let accel_amount = amount * state.scroll_accel;
            // Don't clamp here - render will clamp to actual max_scroll for current panel
            state.scroll_offset += accel_amount;
            state.scroll_accel = (state.scroll_accel + SCROLL_ACCEL_INCREMENT).min(SCROLL_ACCEL_MAX);
            ActionResult::Nothing
        }
        Action::StopStreaming => {
            if state.is_streaming {
                state.is_streaming = false;
                // Remove estimated tokens on cancel
                if let Some(ctx) = state.context.get_mut(state.selected_context) {
                    ctx.token_count = ctx.token_count.saturating_sub(state.streaming_estimated_tokens);
                }
                state.streaming_estimated_tokens = 0;
                // Mark partial response
                if let Some(msg) = state.messages.last_mut() {
                    if msg.role == "assistant" && !msg.content.is_empty() {
                        msg.content.push_str("\n[Stopped]");
                    }
                }
                ActionResult::StopStream
            } else {
                ActionResult::Nothing
            }
        }
        Action::StartContextCleaning => {
            // Don't start if already cleaning (streaming is OK - cleaning runs independently)
            if state.is_cleaning_context {
                ActionResult::Nothing
            } else {
                state.is_cleaning_context = true;
                ActionResult::StartCleaning
            }
        }
        Action::TmuxSendKeys { pane_id, keys } => {
            // Send keys to tmux pane
            use std::process::Command;
            let _ = Command::new("tmux")
                .args(["send-keys", "-t", &pane_id, &keys])
                .output();

            // Update last_keys on the context
            if let Some(ctx) = state.context.iter_mut()
                .find(|c| c.tmux_pane_id.as_ref() == Some(&pane_id))
            {
                ctx.tmux_last_keys = Some(keys);
                // Mark cache as deprecated to refresh the pane content
                ctx.cache_deprecated = true;
            }
            ActionResult::Nothing
        }
        Action::TogglePerfMonitor => {
            state.perf_enabled = crate::perf::PERF.toggle();
            state.dirty = true;
            ActionResult::Nothing
        }
        Action::None => ActionResult::Nothing,
    }
}
